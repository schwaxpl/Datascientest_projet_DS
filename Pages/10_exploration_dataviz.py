import streamlit as st  
import pandas as pd
import numpy as np
from wordcloud import WordCloud
import nltk
from nltk.corpus import stopwords
import seaborn as sns
from statsmodels.tsa.seasonal import seasonal_decompose
import matplotlib.pyplot as plt

if 'reviews_df' in st.session_state:
    df = st.session_state.reviews_df.copy()

    # Extraire les infos sous forme de DataFrame
    df_info = pd.DataFrame({
        "Colonnes": df.columns,
        "Type": df.dtypes.astype(str),
        "Valeurs Non Nul": df.count(),
        "Valeurs Manquantes": df.isna().sum(),
        "% Manquantes": (df.isna().sum() / len(df) * 100).round(2)
    }).reset_index(drop=True)

    tab1, tab2, tab3 = st.tabs(["Colonnes", "Graphiques", "Tests statistiques"])

    with tab1:

        st.write("üìä Informations du DataFrame :")
        st.dataframe(df_info)
        
        st.write("Informations sur les colonnes du DataFrame")
        for column in df.columns:
            with st.expander(f"Colonne: {column}"):
                st.write(f"**{column}**")
                st.write(f"Type: {df[column].dtype}")
                st.write(f"Nombre de valeurs uniques: {df[column].nunique()}")
                st.write(f"Valeurs manquantes: {df[column].isnull().sum()}")
                if df[column].dtype == 'object':
                    st.write("Valeurs les plus fr√©quentes:")
                    st.dataframe(df[column].value_counts().head().reset_index().rename(columns={'index': column, column: 'Count'}))
                else:
                    st.write(f"Statistiques descriptives:")
                    st.dataframe(df[column].describe())
                st.write("---")

    with tab2:
        with st.expander("Histogramme de la r√©partition des notes (v√©rifi√©s vs non v√©rifi√©s)"):
            if df['V√©rifi√©'].dtype == bool:
                verified = df[df['V√©rifi√©'] == True]
                non_verified = df[df['V√©rifi√©'] == False]
            else:
                verified = df[df['V√©rifi√©'] == "V√©rifi√©"]
                non_verified = df[df['V√©rifi√©'] == "Non v√©rifi√©"]

            hist_values_verified = np.histogram(verified['Note'], bins=5, range=(1, 6))[0]
            hist_values_non_verified = np.histogram(non_verified['Note'], bins=5, range=(1, 6))[0]

            bar_width = 0.35
            r1 = np.arange(1, 6)
            r2 = [x + bar_width for x in r1]

            plt.figure()
            plt.bar(r1, hist_values_verified, color='blue', width=bar_width, edgecolor='grey', label='V√©rifi√©s')
            plt.bar(r2, hist_values_non_verified, color='red', width=bar_width, edgecolor='grey', label='Non v√©rifi√©s')

            plt.xlabel('Notes')
            plt.ylabel('Nombre d\'avis')
            plt.xticks([r + bar_width/2 for r in range(1, 6)], [1, 2, 3, 4, 5])
            plt.legend()
            st.pyplot(plt)
            st.write("On peut constater que l'√©norme majorit√© des avis sont positifs, avec une note de 5/5. Ce qui est √©tonnant, car on pourrait s'attendre √† ce que les gens insatisfaits viennent plus souvent s'exprimer.")
            
            st.write("On pourrait penser que les mauvais avis peuvent faire l'objet de mensonges ou de campagne de d√©nigrement de personnes non v√©rifi√©es, v√©rifions.")
            st.write("Distribution des notes (v√©rifi√© / non v√©rifi√© / total) :")
            note_distribution = df.groupby(['Note', 'V√©rifi√©']).size().unstack(fill_value=0)
            note_distribution = note_distribution.div(note_distribution.sum(axis=1), axis=0) * 100
            note_distribution['Total'] = note_distribution.sum(axis=1)
            note_distribution['Total'] = df['Note'].value_counts(normalize=True) * 100
            note_distribution = note_distribution.applymap(lambda x: f"{x:.2f}%")
            st.dataframe(note_distribution)

            verified_avg = verified['Note'].mean()
            non_verified_avg = non_verified['Note'].mean()

            st.write(f"Note moyenne des avis v√©rifi√©s: {verified_avg:.2f}")
            st.write(f"Note moyenne des avis non v√©rifi√©s: {non_verified_avg:.2f}")

            rate_1_verified = len(verified[verified['Note'] == 1]) / len(df[df['Note'] == 1])
            rate_5_verified = len(verified[verified['Note'] == 5]) / len(df[df['Note'] == 5])
            st.write("On a finalement une note moyenne quasiment identique, on constate cependant que les avis une √©toile ont un taux plus important de non v√©rifi√© par rapport aux 5 √©toiles, mais plus globalement que les avis non v√©rifi√©s on tendance √† √™tre plus extremes.")
        with st.expander("Scatterplot entre la longueur des avis et la note"):
            df['Avis_length'] = df['Avis'].fillna("").apply(len)
            plt.figure()
            plt.scatter(df['Note'], df['Avis_length'])
            plt.plot(np.unique(df['Note']), np.poly1d(np.polyfit(df['Note'], df['Avis_length'], 1))(np.unique(df['Note'])), color='red')
            plt.xlabel('Longueur des avis')
            plt.ylabel('Note')
            st.pyplot(plt)
            st.write("On peut constater une l√©g√®re tendance √† ce que les avis plus longs aient tendance √† donner des notes moins √©lev√©es. Ce qui semble logique vu que les gens insatisfaits ont plus de choses √† dire et de motivation √† d√©tailler leur avis.")
        
        with st.expander("Taux de r√©ponse aux avis et note moyenne par entreprise"):
            response_rate = df['R√©ponse'].apply(lambda x: not pd.isnull(x) and x != "Pas de r√©ponse").groupby(df['Entreprise']).mean()
            average_rating = df.groupby('Entreprise')['Note'].mean()

            fig, ax1 = plt.subplots()

            ax1.set_xlabel('Note moyenne')
            ax1.set_ylabel('Taux de r√©ponse')
            ax1.set_ylim(0, 1.0)  # Limiter l'axe y √† 1.0 maximum
            ax1.scatter(average_rating.values, response_rate.values, color='blue', marker='o')
            sns.regplot(x=average_rating.values, y=response_rate.values, ax=ax1, color='red', scatter=False)
            fig.tight_layout()
            st.pyplot(fig)

            st.text("On peut constater que les entreprises ayant une note moyenne plus √©lev√©e ont tendance √† r√©pondre moins souvent aux avis. Ce qui tendrait √† indiquer que les entreprises ayant une meilleure r√©putation n'ont pas besoin de r√©pondre √† tous les avis pour maintenir leur image, et qu'√† l'inverse, les entreprises avec de moins bonnes notes sont soucieuses d'am√©liorer leur image et de r√©pondre √† leurs avis.")

        with st.expander("√âvolution dans le temps"):
            df['Date'] = pd.to_datetime(df['Date'])
            df.set_index('Date', inplace=True)

            fig, ax = plt.subplots(3, 1, figsize=(10, 15))

            df['Note'].resample('M').mean().plot(ax=ax[0], color='blue')
            ax[0].set_title('√âvolution des notes moyennes par mois')
            ax[0].set_xlabel('Date')
            ax[0].set_ylabel('Note moyenne')

            df['Avis_length'].resample('M').mean().plot(ax=ax[1], color='green')
            ax[1].set_title('√âvolution de la longueur moyenne des avis par mois')
            ax[1].set_xlabel('Date')
            ax[1].set_ylabel('Longueur moyenne des avis')

            df['Avis'].resample('M').count().plot(ax=ax[2], color='purple')
            ax[2].set_title('√âvolution du nombre d\'avis par mois')
            ax[2].set_xlabel('Date')
            ax[2].set_ylabel('Nombre d\'avis')

            plt.tight_layout()
            st.pyplot(fig)

            st.text("Les deux premiers graphiques ne montrent pas de tendance int√©ressante, par contre le dernier montre deux choses : une apparente saisonnalit√© dans le d√©p√¥t d'avis, et surtout une apparente croissance du nombre d'avis.")
            st.text("On constate plusieurs trous dans les courbes, pas assez de data sur ces p√©riodes ? pertes de donn√©es ?")
        with st.expander("Analyse de la saisonnalit√© du nombre d'avis"):
            df['Month'] = df.index.month
            monthly_reviews = df['Avis'].groupby(df['Month']).count()

            plt.figure(figsize=(10, 6))
            sns.barplot(x=monthly_reviews.index, y=monthly_reviews.values, palette='viridis')
            plt.xlabel('Mois')
            plt.ylabel('Nombre d\'avis')
            plt.title('Nombre d\'avis par mois')
            st.pyplot(plt)

            st.write("On peut observer un nombre d'avis plus important en d√©but d'ann√©e, date d'entr√©e / sortie de la plupart des promos ? On constate aussi un creux en ao√ªt explicable par les cong√©s et la baisse d'activit√© sur les formations ainsi qu'en avril-mai, o√π on peut penser que la plupart des formations sont en cours et donc que les gens n'en sont pas encore au moment de s'exprimer.")
        with st.expander("Analyse de la tendance en √©liminant la saisonnalit√©"):

            # D√©composer la s√©rie temporelle
            decomposition = seasonal_decompose(df['Avis'].resample('M').count(), model='additive')
            trend = decomposition.trend

            plt.figure(figsize=(10, 6))
            plt.plot(trend, label='Tendance', color='blue')
            plt.xlabel('Date')
            plt.ylabel('Nombre d\'avis')
            plt.title('Tendance du nombre d\'avis par mois (sans saisonnalit√©)')
            plt.legend()
            st.pyplot(plt)

            st.write("La tendance montre effectivement une croissance, rendant d'autant plus int√©ressante notre solution puisque plus on a d'avis, plus cela n√©cessite de travail de r√©ponse.")
            #TODO: Analyse du nombre d'avis par entreprise
        with st.expander("Nuage de mots des mots les plus fr√©quents par note"):
            nltk.download('stopwords')
            stop_words = set(stopwords.words('french'))
            additional_stop_words = ["formation", "j'ai", "c'est", "√™tre","a","n'est","comme","d'un"]
            stop_words.update(additional_stop_words)
            for note in range(1, 6):
                st.subheader(f"Note {note}")
                text = " ".join(review for review in df[df['Note'] == note]['Avis'].dropna())
                text = " ".join(word for word in text.split() if word.lower() not in stop_words)

                wordcloud = WordCloud(max_font_size=50, max_words=100, background_color="white", min_word_length=4).generate(text)

                plt.figure()
                plt.imshow(wordcloud, interpolation="bilinear")
                plt.axis("off")
                st.pyplot(plt)
            st.write("Difficile de tirer des conclusions sans plus de nettoyage et d'affinage, quelques mots importants ressortent cependant : Site, plateforme, formateur, accompagnement, suivi. \n Ces th√®mes sont donc probablement importants dans le cadre d'une formation en ligne. ")

    with tab3:
        st.write("Tests statistiques √† venir")
